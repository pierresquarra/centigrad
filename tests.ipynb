{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dd32b9ac19d65e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neural Networks from Scratch\n",
    "\n",
    "Following a YouTube tutorial\n",
    "\n",
    "## Hardcoding inputs, weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.362499500Z",
     "start_time": "2023-09-13T11:02:58.344562800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "          [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220233102fd0fad7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Testing out zip() and for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d456920b4540b9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.362499500Z",
     "start_time": "2023-09-13T11:02:58.348455500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.8, -0.5, 1.0] 2\n",
      "[0.5, -0.91, 0.26, -0.5] 3\n",
      "[-0.26, -0.27, 0.17, 0.87] 0.5\n"
     ]
    }
   ],
   "source": [
    "a = zip(weights, biases)\n",
    "for neuron_weights, neuron_bias in a:\n",
    "    print(neuron_weights, neuron_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263da49091646b1f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hardcoding dot product of weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8b66c569d6b58a8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.362499500Z",
     "start_time": "2023-09-13T11:02:58.355659800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "layer_outputs = [] # Output of the current layer\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    neuron_output = 0 # Output of a given neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        neuron_output += n_input*weight\n",
    "    neuron_output += neuron_bias\n",
    "    layer_outputs.append(neuron_output)\n",
    "\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277dc52b2ec014fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Looking at numpy arrays and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9230a8e57ac71763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.431934300Z",
     "start_time": "2023-09-13T11:02:58.360500700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) (2, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l = np.array([1,5,6,2])\n",
    "lol = np.array([[1,5,6,2],\n",
    "              [3,2,1,3]])\n",
    "print(l.shape, lol.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb97d054d03f274",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Checking out numpy.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10a1522cf3fa4fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.436968400Z",
     "start_time": "2023-09-13T11:02:58.430935100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "\n",
    "dot_product = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]\n",
    "print(dot_product)\n",
    "print(np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccaa398767ce83e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analyzing shape for dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "884bd9b168e2163c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.441566400Z",
     "start_time": "2023-09-13T11:02:58.436968400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "outputs = np.dot(weights, inputs) + biases\n",
    "# wrong_order = np.dot(inputs, weights) + biases\n",
    "print(outputs)\n",
    "# print(wrong_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554800fdfdc8c53",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using a batch of inputs instead of a single set of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec2c631c3518146c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.446084800Z",
     "start_time": "2023-09-13T11:02:58.442567Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "input_batch = [[1,2,3,2.5],\n",
    "               [2.0,5.0, -1.0, 2-0],\n",
    "               [-1.5, 2.7, 3.3, -0.8]]\n",
    "# dot product doesn't work anymore, because input shape changed\n",
    "# outputs = np.dot(weights, input_batch) + biases\n",
    "outputs = np.dot(input_batch, np.transpose(weights)) + biases\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e724fff7b0d55e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Adding a second layer by hand and passing data through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5b19b42ac31273c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.453230Z",
     "start_time": "2023-09-13T11:02:58.448091700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "            [-0.5, 0.12, -0.33],\n",
    "            [-0.44, 0.73, -0.13]]\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(input_batch, np.transpose(weights)) + biases\n",
    "layer2_outputs = np.dot(layer1_outputs, np.transpose(weights2)) + biases2\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d4bc104e5558ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining a DenseLayer class with forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "bca34e8a28f42d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:21:00.695220300Z",
     "start_time": "2023-09-13T11:21:00.690322500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "X = [[1, 2, 3, 2.5],\n",
    "      [2.0, 5.0, -1.0, 2-0],\n",
    "      [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        \n",
    "# print(0.1*np.random.randn(4, 3))\n",
    "\n",
    "layer1 = DenseLayer(4, 5)\n",
    "layer2 = DenseLayer(5, 2)\n",
    "\n",
    "layer1.forward(X)\n",
    "# print(layer1.output)\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf914c61aef744",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "413705744620750e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T12:00:43.752025600Z",
     "start_time": "2023-09-13T12:00:43.748998800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 0, 3.3, 0, 1.1, 2.2, 0]\n"
     ]
    }
   ],
   "source": [
    "inputs = [0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
    "output = []\n",
    "\n",
    "for i in inputs:\n",
    "    output.append(max(0, i))\n",
    "        \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "76c25c21e4807cb0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d647e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createData(points, classes):\n",
    "    X = np.zeros((points*classes, 2))\n",
    "    y = np.zeros(points*classes, dtype='uint8')\n",
    "    for class_number in range(classes):\n",
    "        ix = range(points*class_number, points*(class_number+1))\n",
    "        r = np.linspace(0.0, 1, points)\n",
    "        t = np.linspace(class_number*4, (class_number+1)*4, points) + np.random.randn(points)*0.2\n",
    "        X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
    "        y[ix] = class_number\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d76c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotData(X, y):\n",
    "    plt.scatter(X[:,0], X[:,1])\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=\"brg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "fdb10426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.         0.         0.         0.         0.        ]\n",
      " [0.00080274 0.         0.00065987 0.         0.00083796]\n",
      " [0.00082768 0.         0.0005103  0.         0.00454176]\n",
      " ...\n",
      " [0.01800099 0.         0.00336391 0.         0.26602511]\n",
      " [0.         0.16360456 0.         0.13192221 0.20328078]\n",
      " [0.         0.         0.         0.05579987 0.31271706]]\n"
     ]
    }
   ],
   "source": [
    "X, y = createData(100, 3)\n",
    "# plotData(X, y)\n",
    "\n",
    "layer1 = DenseLayer(2, 5)\n",
    "activation1 = ReLU()\n",
    "\n",
    "layer1.forward(X)\n",
    "\n",
    "activation1.forward(layer1.output)\n",
    "print(activation1.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe4807",
   "metadata": {},
   "source": [
    "## Softmax Activation\n",
    "\n",
    "### Exponantiation to get rid of negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "35f468ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "layer_outputs = [4.8, 1.21, 2.385]\n",
    "E = math.e\n",
    "\n",
    "exp_values = []\n",
    "for output in layer_outputs:\n",
    "    exp_values.append(E**output)\n",
    "\n",
    "print(exp_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf1dc5",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0ed154f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8952826639572619, 0.024708306782099374, 0.0800090292606387]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "norm_base = sum(exp_values)\n",
    "norm_values = []\n",
    "\n",
    "for value in exp_values:\n",
    "    norm_values.append(value / norm_base)\n",
    "\n",
    "print(norm_values)\n",
    "print(sum(norm_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66a043",
   "metadata": {},
   "source": [
    "### Using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4adcaa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89528266 0.02470831 0.08000903]\n"
     ]
    }
   ],
   "source": [
    "exp_values = np.exp(layer_outputs)\n",
    "norm_values = exp_values / np.sum(exp_values)\n",
    "\n",
    "print(norm_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a3fcb",
   "metadata": {},
   "source": [
    "### Turning input into batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ae27a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.95282664e-01 2.47083068e-02 8.00090293e-02]\n",
      " [9.99811129e-01 2.23163963e-05 1.66554348e-04]\n",
      " [5.13097164e-01 3.58333899e-01 1.28568936e-01]]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "layer_outputs = [[4.8, 1.21, 2.385],\n",
    "                 [8.9, -1.81, 0.2],\n",
    "                 [1.41, 1.051, 0.026]]\n",
    "\n",
    "exp_values = np.exp(layer_outputs)\n",
    "norm_values = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "print(norm_values)\n",
    "print(norm_values[0][0] + norm_values[0][1] + norm_values[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "495c9d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]\n",
      " [0.33333333 0.33333333 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "class Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilites = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilites\n",
    "\n",
    "X, y = createData(100, 3)\n",
    "\n",
    "dense1 = DenseLayer(2, 3)\n",
    "activation1 = ReLU()\n",
    "dense2 = DenseLayer(3, 3)\n",
    "activation2 = Softmax()\n",
    "\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e8e1e",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "### Categorical Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "a7e72ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n",
      "0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "softmax_output = [0.7, 0.1, 0.2]\n",
    "target_output = [1, 0, 0] # one-hot encoding\n",
    "\n",
    "loss = -(np.log(softmax_output[0])*target_output[0] + \n",
    "         np.log(softmax_output[1])*target_output[1] + \n",
    "         np.log(softmax_output[2])*target_output[2])\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss = -(np.log(softmax_output[0]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.5 0.9]\n",
      "[0.7 0.5 0.9]\n",
      "0.38506088005216804\n"
     ]
    }
   ],
   "source": [
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    "                            [0.1, 0.5, 0.4],\n",
    "                            [0.02, 0.9, 0.08]])\n",
    "\n",
    "class_targets = [0, 1, 1] # for example, 0 means cat, 1 means dog, 2 means pigeon, so here the first input is a cat and the two others are dogs\n",
    "\n",
    "print(softmax_outputs[[0,1,2], class_targets]) # numpy magic, [0,1,2] selects all three rows of inputs\n",
    "print(softmax_outputs[range(len(softmax_outputs)), class_targets])\n",
    "\n",
    "neg_loss = -np.log(softmax_outputs[range(len(softmax_outputs)), class_targets])\n",
    "avg_loss = np.mean(neg_loss)\n",
    "print(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344ada8",
   "metadata": {},
   "source": [
    "**Problem:** neagtive log of 0 is infinity which results in errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "19295096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.0980680308591275\n"
     ]
    }
   ],
   "source": [
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "\n",
    "class CategoricalCrossentropy(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7) # to resovle our problem\n",
    "\n",
    "        # check if scalar values or one hot encoded values have been passed\n",
    "        # scalar: [0, 1]\n",
    "        # one-hot encoded: [[1,0],[0,1]]\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "        else:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "loss_function = CategoricalCrossentropy()\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "print(\"Loss: \", loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3097f61",
   "metadata": {},
   "source": [
    "## Optimization\n",
    "\n",
    "### Random adjustment of weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c00e1d8e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of weights found, iteration: 0 loss: 1.0995347495967274 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 2 loss: 1.098922828015789 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 8 loss: 1.0985118206616498 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 14 loss: 1.0984489065242378 acc: 0.3333333333333333\n",
      "New set of weights found, iteration: 17 loss: 1.097436060523383 acc: 0.3433333333333333\n",
      "New set of weights found, iteration: 22 loss: 1.0971097128231166 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 33 loss: 1.0966510923150883 acc: 0.35333333333333333\n",
      "New set of weights found, iteration: 37 loss: 1.0963794169836545 acc: 0.37\n",
      "New set of weights found, iteration: 40 loss: 1.0960531146473522 acc: 0.3566666666666667\n",
      "New set of weights found, iteration: 46 loss: 1.0956507180565485 acc: 0.3566666666666667\n",
      "New set of weights found, iteration: 47 loss: 1.0934543942627015 acc: 0.39666666666666667\n",
      "New set of weights found, iteration: 67 loss: 1.0924688371327613 acc: 0.38333333333333336\n",
      "New set of weights found, iteration: 70 loss: 1.092241585744668 acc: 0.36333333333333334\n",
      "New set of weights found, iteration: 82 loss: 1.0921558486626415 acc: 0.38333333333333336\n",
      "New set of weights found, iteration: 83 loss: 1.0918893828634249 acc: 0.37333333333333335\n",
      "New set of weights found, iteration: 85 loss: 1.091729469466967 acc: 0.37\n",
      "New set of weights found, iteration: 91 loss: 1.090495841316157 acc: 0.36666666666666664\n",
      "New set of weights found, iteration: 104 loss: 1.0895008011954845 acc: 0.36666666666666664\n",
      "New set of weights found, iteration: 115 loss: 1.0894618746393114 acc: 0.38666666666666666\n",
      "New set of weights found, iteration: 116 loss: 1.0885036109396153 acc: 0.38666666666666666\n",
      "New set of weights found, iteration: 123 loss: 1.0883249991178623 acc: 0.3566666666666667\n",
      "New set of weights found, iteration: 124 loss: 1.0854771911840337 acc: 0.42\n",
      "New set of weights found, iteration: 131 loss: 1.0850499491889185 acc: 0.4\n",
      "New set of weights found, iteration: 139 loss: 1.082791548115798 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 142 loss: 1.082632880786241 acc: 0.4\n",
      "New set of weights found, iteration: 145 loss: 1.0808349320549335 acc: 0.36666666666666664\n",
      "New set of weights found, iteration: 146 loss: 1.0793743103211575 acc: 0.39666666666666667\n",
      "New set of weights found, iteration: 151 loss: 1.079165820243084 acc: 0.3933333333333333\n",
      "New set of weights found, iteration: 153 loss: 1.0781805481289366 acc: 0.38333333333333336\n",
      "New set of weights found, iteration: 157 loss: 1.0772460388462684 acc: 0.4033333333333333\n",
      "New set of weights found, iteration: 158 loss: 1.0753070468907195 acc: 0.3933333333333333\n",
      "New set of weights found, iteration: 171 loss: 1.073960911179232 acc: 0.39\n",
      "New set of weights found, iteration: 173 loss: 1.0715821597020336 acc: 0.4166666666666667\n",
      "New set of weights found, iteration: 180 loss: 1.0714301099690928 acc: 0.4033333333333333\n",
      "New set of weights found, iteration: 184 loss: 1.0707067699236468 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 185 loss: 1.0691844654652563 acc: 0.4033333333333333\n",
      "New set of weights found, iteration: 216 loss: 1.0686665987340866 acc: 0.3933333333333333\n",
      "New set of weights found, iteration: 233 loss: 1.0679248024993069 acc: 0.41\n",
      "New set of weights found, iteration: 248 loss: 1.0670169639616036 acc: 0.42333333333333334\n",
      "New set of weights found, iteration: 250 loss: 1.0664607138198499 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 255 loss: 1.065516102267393 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 260 loss: 1.0647171967801272 acc: 0.41\n",
      "New set of weights found, iteration: 265 loss: 1.0643473157731775 acc: 0.4033333333333333\n",
      "New set of weights found, iteration: 266 loss: 1.0642545092096607 acc: 0.42\n",
      "New set of weights found, iteration: 278 loss: 1.063759013354082 acc: 0.41\n",
      "New set of weights found, iteration: 280 loss: 1.0632200436549875 acc: 0.4166666666666667\n",
      "New set of weights found, iteration: 281 loss: 1.0628702893144018 acc: 0.41\n",
      "New set of weights found, iteration: 285 loss: 1.062669040227437 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 298 loss: 1.0625175904554154 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 313 loss: 1.0622231100324813 acc: 0.4033333333333333\n",
      "New set of weights found, iteration: 317 loss: 1.062032135024801 acc: 0.3933333333333333\n",
      "New set of weights found, iteration: 323 loss: 1.0616757946952982 acc: 0.4166666666666667\n",
      "New set of weights found, iteration: 343 loss: 1.061617281963208 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 398 loss: 1.060893741191642 acc: 0.4166666666666667\n",
      "New set of weights found, iteration: 400 loss: 1.0606719167347596 acc: 0.42333333333333334\n",
      "New set of weights found, iteration: 401 loss: 1.0605500541282245 acc: 0.43\n",
      "New set of weights found, iteration: 413 loss: 1.0600654256087978 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 415 loss: 1.0593557588296025 acc: 0.42\n",
      "New set of weights found, iteration: 433 loss: 1.0592735159693363 acc: 0.3933333333333333\n",
      "New set of weights found, iteration: 440 loss: 1.0588579192818302 acc: 0.39666666666666667\n",
      "New set of weights found, iteration: 446 loss: 1.0586526105389675 acc: 0.42333333333333334\n",
      "New set of weights found, iteration: 468 loss: 1.0584243467796257 acc: 0.42333333333333334\n",
      "New set of weights found, iteration: 557 loss: 1.0580637772670052 acc: 0.42333333333333334\n",
      "New set of weights found, iteration: 748 loss: 1.0578112076062902 acc: 0.41333333333333333\n",
      "New set of weights found, iteration: 835 loss: 1.057343719003716 acc: 0.43\n",
      "New set of weights found, iteration: 863 loss: 1.0570584659930997 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 868 loss: 1.057022500203734 acc: 0.44\n",
      "New set of weights found, iteration: 906 loss: 1.056697931811597 acc: 0.42\n",
      "New set of weights found, iteration: 908 loss: 1.0563976589830597 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 972 loss: 1.0562657893889547 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 1032 loss: 1.0558411585691239 acc: 0.44\n",
      "New set of weights found, iteration: 1049 loss: 1.054736475516102 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 1073 loss: 1.054725587166339 acc: 0.44\n",
      "New set of weights found, iteration: 1123 loss: 1.054718894705742 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 1160 loss: 1.0546161578414421 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 1170 loss: 1.053520409261768 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 1178 loss: 1.0531344868777015 acc: 0.44\n",
      "New set of weights found, iteration: 1190 loss: 1.0528513091929115 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 1208 loss: 1.0526894841541294 acc: 0.41333333333333333\n",
      "New set of weights found, iteration: 1209 loss: 1.052465143172904 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 1211 loss: 1.0523839669865922 acc: 0.42333333333333334\n",
      "New set of weights found, iteration: 1224 loss: 1.0519121746678721 acc: 0.4166666666666667\n",
      "New set of weights found, iteration: 1230 loss: 1.0502106326227745 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 1261 loss: 1.0501123364960687 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 1279 loss: 1.0498532674576606 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 1313 loss: 1.0497475501078817 acc: 0.41333333333333333\n",
      "New set of weights found, iteration: 1317 loss: 1.04900119583386 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 1324 loss: 1.0486522195680017 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 1390 loss: 1.048631447112394 acc: 0.44\n",
      "New set of weights found, iteration: 1472 loss: 1.0486232715725794 acc: 0.44\n",
      "New set of weights found, iteration: 1504 loss: 1.0482730116308536 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 1506 loss: 1.0481889657319994 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 1515 loss: 1.0477547678446208 acc: 0.42333333333333334\n",
      "New set of weights found, iteration: 1553 loss: 1.0476184257845897 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 1560 loss: 1.0474615446023514 acc: 0.41333333333333333\n",
      "New set of weights found, iteration: 1568 loss: 1.047052843162873 acc: 0.45\n",
      "New set of weights found, iteration: 1569 loss: 1.0461094858440634 acc: 0.44\n",
      "New set of weights found, iteration: 1597 loss: 1.0459870255016086 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 2142 loss: 1.0459519777094748 acc: 0.43\n",
      "New set of weights found, iteration: 2599 loss: 1.0458875430721029 acc: 0.4266666666666667\n",
      "New set of weights found, iteration: 2672 loss: 1.0457482034487953 acc: 0.45\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "New set of weights found, iteration: 4288 loss: 1.0455498145609585 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 4774 loss: 1.0455337433010194 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 4791 loss: 1.0454022873633046 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 4920 loss: 1.0450987837947907 acc: 0.45\n",
      "New set of weights found, iteration: 5067 loss: 1.0447649000505983 acc: 0.44\n",
      "New set of weights found, iteration: 5178 loss: 1.0444599840345479 acc: 0.46\n",
      "New set of weights found, iteration: 5361 loss: 1.0442217068020012 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 5372 loss: 1.0441951376214929 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 6238 loss: 1.0440896922499492 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 7868 loss: 1.0440751638027457 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 7959 loss: 1.0439000866669528 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 8191 loss: 1.043563561040312 acc: 0.44\n",
      "New set of weights found, iteration: 8809 loss: 1.043547535644911 acc: 0.44\n",
      "New set of weights found, iteration: 8848 loss: 1.0433762338839052 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 9221 loss: 1.0432094983776479 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 9393 loss: 1.0432056929441778 acc: 0.44\n",
      "New set of weights found, iteration: 9424 loss: 1.0429416123310484 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 9427 loss: 1.0429374592832443 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 9499 loss: 1.0424376951100185 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 9590 loss: 1.0420782643766946 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 9814 loss: 1.0419269159450764 acc: 0.44\n",
      "New set of weights found, iteration: 9903 loss: 1.0415979792866885 acc: 0.42\n",
      "New set of weights found, iteration: 9921 loss: 1.04131432226729 acc: 0.46\n",
      "New set of weights found, iteration: 10685 loss: 1.0412504674327776 acc: 0.45\n",
      "New set of weights found, iteration: 11782 loss: 1.0411537038545524 acc: 0.45\n",
      "New set of weights found, iteration: 12830 loss: 1.0411446549931607 acc: 0.45\n",
      "New set of weights found, iteration: 13116 loss: 1.0411380206540692 acc: 0.45\n",
      "New set of weights found, iteration: 13239 loss: 1.041093494512064 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 13557 loss: 1.0408593587400912 acc: 0.47333333333333333\n",
      "New set of weights found, iteration: 13968 loss: 1.0406487050093536 acc: 0.46\n",
      "New set of weights found, iteration: 15044 loss: 1.0404656557094147 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 15341 loss: 1.04040001420502 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 17456 loss: 1.0403845826910405 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 17463 loss: 1.04017859834999 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 18627 loss: 1.040049210415023 acc: 0.4633333333333333\n",
      "New set of weights found, iteration: 18784 loss: 1.040038708472775 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 18849 loss: 1.0398451804028515 acc: 0.46\n",
      "New set of weights found, iteration: 19302 loss: 1.0395866994205618 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 36219 loss: 1.0394695376905394 acc: 0.46\n",
      "New set of weights found, iteration: 37778 loss: 1.0393580643862983 acc: 0.45\n",
      "New set of weights found, iteration: 38924 loss: 1.039110970317048 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 39032 loss: 1.0391045266202943 acc: 0.44\n",
      "New set of weights found, iteration: 40451 loss: 1.0390227796693243 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 42859 loss: 1.0389712858364095 acc: 0.4633333333333333\n",
      "New set of weights found, iteration: 43085 loss: 1.0389360322939083 acc: 0.43333333333333335\n",
      "New set of weights found, iteration: 43636 loss: 1.0387818093836536 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 43860 loss: 1.0387751722547025 acc: 0.44\n",
      "New set of weights found, iteration: 45960 loss: 1.0386715501465438 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 45967 loss: 1.0385436662796004 acc: 0.45666666666666667\n",
      "New set of weights found, iteration: 46495 loss: 1.0383531952163778 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 49506 loss: 1.038336022263624 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 52373 loss: 1.0382939823384725 acc: 0.45666666666666667\n",
      "New set of weights found, iteration: 54822 loss: 1.038204203997051 acc: 0.45\n",
      "New set of weights found, iteration: 59140 loss: 1.0381517655295516 acc: 0.45666666666666667\n",
      "New set of weights found, iteration: 61864 loss: 1.0381482905114625 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 62712 loss: 1.0381207779512358 acc: 0.44666666666666666\n",
      "New set of weights found, iteration: 62943 loss: 1.037764040737959 acc: 0.45666666666666667\n",
      "New set of weights found, iteration: 65556 loss: 1.03770680456256 acc: 0.43\n",
      "New set of weights found, iteration: 66117 loss: 1.0376517673035643 acc: 0.44\n",
      "New set of weights found, iteration: 66205 loss: 1.0375686175322618 acc: 0.45666666666666667\n",
      "New set of weights found, iteration: 79627 loss: 1.0375356884578413 acc: 0.46\n",
      "New set of weights found, iteration: 80691 loss: 1.0375115919428317 acc: 0.4633333333333333\n",
      "New set of weights found, iteration: 81115 loss: 1.03736191347871 acc: 0.44\n",
      "New set of weights found, iteration: 89695 loss: 1.0372663295802442 acc: 0.4533333333333333\n",
      "New set of weights found, iteration: 89717 loss: 1.0371344950203365 acc: 0.45666666666666667\n",
      "New set of weights found, iteration: 94968 loss: 1.0371295345342013 acc: 0.46\n",
      "New set of weights found, iteration: 95218 loss: 1.0370789616105505 acc: 0.44333333333333336\n",
      "New set of weights found, iteration: 98797 loss: 1.0370415903816677 acc: 0.45\n",
      "New set of weights found, iteration: 98905 loss: 1.0368872214247495 acc: 0.42333333333333334\n",
      "New set of weights found, iteration: 99374 loss: 1.0368599006929735 acc: 0.43666666666666665\n",
      "New set of weights found, iteration: 99610 loss: 1.036713832909832 acc: 0.4666666666666667\n"
     ]
    }
   ],
   "source": [
    "X, y = createData(100, 3)\n",
    "\n",
    "dense1 = DenseLayer(2, 3)\n",
    "activation1 = ReLU()\n",
    "dense2 = DenseLayer(3, 3)\n",
    "activation2 = Softmax()\n",
    "\n",
    "loss_function = CategoricalCrossentropy()\n",
    "\n",
    "lowest_loss = 999999\n",
    "best_dense1_weights = dense1.weights.copy()\n",
    "best_dense1_biases = dense1.biases.copy()\n",
    "best_dense2_weights = dense2.weights.copy()\n",
    "best_dense2_biases = dense2.biases.copy()\n",
    "\n",
    "for iteration in range(100000):\n",
    "    dense1.weights += 0.05 * np.random.randn(2, 3)\n",
    "    dense1.biases += 0.05 * np.random.randn(1, 3)\n",
    "    dense2.weights += 0.05 * np.random.randn(3, 3)\n",
    "    dense2.biases += 0.05 * np.random.randn(1, 3)\n",
    "\n",
    "    dense1.forward(X)\n",
    "    activation1.forward(dense1.output)\n",
    "    dense2.forward(activation1.output)\n",
    "    activation2.forward(dense2.output)\n",
    "\n",
    "    loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "    predictions = np.argmax(activation2.output, axis=1)\n",
    "    accuracy = np.mean(predictions==y)\n",
    "\n",
    "    if loss < lowest_loss:\n",
    "        print(\"New set of weights found, iteration:\", iteration, \"loss:\", loss, \"acc:\", accuracy)\n",
    "        best_dense1_weights = dense1.weights.copy()\n",
    "        best_dense1_biases = dense1.biases.copy()\n",
    "        best_dense2_weights = dense2.weights.copy()\n",
    "        best_dense2_biases = dense2.biases.copy()\n",
    "        lowest_loss = loss\n",
    "    else:\n",
    "        dense1.weights = best_dense1_weights.copy()\n",
    "        dense1.biases = best_dense1_biases.copy()\n",
    "        dense2.weights = best_dense2_weights.copy()\n",
    "        dense2.biases = best_dense2_biases.copy()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
