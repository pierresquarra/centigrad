{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c0dd32b9ac19d65e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Neural Networks from Scratch\n",
    "\n",
    "Following a YouTube tutorial\n",
    "\n",
    "## Hardcoding inputs, weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "initial_id",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.362499500Z",
     "start_time": "2023-09-13T11:02:58.344562800Z"
    },
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputs = [1, 2, 3, 2.5]\n",
    "weights = [[0.2, 0.8, -0.5, 1.0],\n",
    "          [0.5, -0.91, 0.26, -0.5],\n",
    "          [-0.26, -0.27, 0.17, 0.87]]\n",
    "biases = [2, 3, 0.5]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220233102fd0fad7",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Testing out zip() and for loops"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d456920b4540b9eb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.362499500Z",
     "start_time": "2023-09-13T11:02:58.348455500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.2, 0.8, -0.5, 1.0] 2\n",
      "[0.5, -0.91, 0.26, -0.5] 3\n",
      "[-0.26, -0.27, 0.17, 0.87] 0.5\n"
     ]
    }
   ],
   "source": [
    "a = zip(weights, biases)\n",
    "for neuron_weights, neuron_bias in a:\n",
    "    print(neuron_weights, neuron_bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "263da49091646b1f",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Hardcoding dot product of weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8b66c569d6b58a8f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.362499500Z",
     "start_time": "2023-09-13T11:02:58.355659800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8, 1.21, 2.385]\n"
     ]
    }
   ],
   "source": [
    "layer_outputs = [] # Output of the current layer\n",
    "for neuron_weights, neuron_bias in zip(weights, biases):\n",
    "    neuron_output = 0 # Output of a given neuron\n",
    "    for n_input, weight in zip(inputs, neuron_weights):\n",
    "        neuron_output += n_input*weight\n",
    "    neuron_output += neuron_bias\n",
    "    layer_outputs.append(neuron_output)\n",
    "\n",
    "print(layer_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "277dc52b2ec014fc",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Looking at numpy arrays and matrices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9230a8e57ac71763",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.431934300Z",
     "start_time": "2023-09-13T11:02:58.360500700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4,) (2, 4)\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "l = np.array([1,5,6,2])\n",
    "lol = np.array([[1,5,6,2],\n",
    "              [3,2,1,3]])\n",
    "print(l.shape, lol.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb97d054d03f274",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Checking out numpy.dot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "10a1522cf3fa4fa6",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.436968400Z",
     "start_time": "2023-09-13T11:02:58.430935100Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n",
      "20\n"
     ]
    }
   ],
   "source": [
    "a = [1,2,3]\n",
    "b = [2,3,4]\n",
    "\n",
    "dot_product = a[0]*b[0] + a[1]*b[1] + a[2]*b[2]\n",
    "print(dot_product)\n",
    "print(np.dot(a, b))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ccaa398767ce83e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Analyzing shape for dot product"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "884bd9b168e2163c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.441566400Z",
     "start_time": "2023-09-13T11:02:58.436968400Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[4.8   1.21  2.385]\n"
     ]
    }
   ],
   "source": [
    "outputs = np.dot(weights, inputs) + biases\n",
    "# wrong_order = np.dot(inputs, weights) + biases\n",
    "print(outputs)\n",
    "# print(wrong_order)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d554800fdfdc8c53",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Using a batch of inputs instead of a single set of inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ec2c631c3518146c",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.446084800Z",
     "start_time": "2023-09-13T11:02:58.442567Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 4.8    1.21   2.385]\n",
      " [ 8.9   -1.81   0.2  ]\n",
      " [ 1.41   1.051  0.026]]\n"
     ]
    }
   ],
   "source": [
    "input_batch = [[1,2,3,2.5],\n",
    "               [2.0,5.0, -1.0, 2-0],\n",
    "               [-1.5, 2.7, 3.3, -0.8]]\n",
    "# dot product doesn't work anymore, because input shape changed\n",
    "# outputs = np.dot(weights, input_batch) + biases\n",
    "outputs = np.dot(input_batch, np.transpose(weights)) + biases\n",
    "print(outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96e724fff7b0d55e",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Adding a second layer by hand and passing data through"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b19b42ac31273c5",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:02:58.453230Z",
     "start_time": "2023-09-13T11:02:58.448091700Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.5031  -1.04185 -2.03875]\n",
      " [ 0.2434  -2.7332  -5.7633 ]\n",
      " [-0.99314  1.41254 -0.35655]]\n"
     ]
    }
   ],
   "source": [
    "weights2 = [[0.1, -0.14, 0.5],\n",
    "            [-0.5, 0.12, -0.33],\n",
    "            [-0.44, 0.73, -0.13]]\n",
    "biases2 = [-1, 2, -0.5]\n",
    "\n",
    "layer1_outputs = np.dot(input_batch, np.transpose(weights)) + biases\n",
    "layer2_outputs = np.dot(layer1_outputs, np.transpose(weights2)) + biases2\n",
    "\n",
    "print(layer2_outputs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3d4bc104e5558ae",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining a DenseLayer class with forward method"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bca34e8a28f42d72",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T11:21:00.695220300Z",
     "start_time": "2023-09-13T11:21:00.690322500Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 0.148296   -0.08397602]\n",
      " [ 0.14100315 -0.01340469]\n",
      " [ 0.20124979 -0.07290616]]\n"
     ]
    }
   ],
   "source": [
    "X = [[1, 2, 3, 2.5],\n",
    "      [2.0, 5.0, -1.0, 2-0],\n",
    "      [-1.5, 2.7, 3.3, -0.8]]\n",
    "\n",
    "np.random.seed(0)\n",
    "\n",
    "class DenseLayer:\n",
    "    def __init__(self, n_inputs, n_neurons):\n",
    "        self.weights = 0.1 * np.random.randn(n_inputs, n_neurons)\n",
    "        self.biases = np.zeros((1, n_neurons))\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.dot(inputs, self.weights) + self.biases\n",
    "        \n",
    "# print(0.1*np.random.randn(4, 3))\n",
    "\n",
    "layer1 = DenseLayer(4, 5)\n",
    "layer2 = DenseLayer(5, 2)\n",
    "\n",
    "layer1.forward(X)\n",
    "# print(layer1.output)\n",
    "layer2.forward(layer1.output)\n",
    "print(layer2.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eebf914c61aef744",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "## Defining ReLU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "413705744620750e",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-09-13T12:00:43.752025600Z",
     "start_time": "2023-09-13T12:00:43.748998800Z"
    },
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 2, 0, 3.3, 0, 1.1, 2.2, 0]\n"
     ]
    }
   ],
   "source": [
    "inputs = [0, 2, -1, 3.3, -2.7, 1.1, 2.2, -100]\n",
    "output = []\n",
    "\n",
    "for i in inputs:\n",
    "    output.append(max(0, i))\n",
    "        \n",
    "print(output)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "76c25c21e4807cb0",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ReLU:\n",
    "    def forward(self, inputs):\n",
    "        self.output = np.maximum(0, inputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "9d647e44",
   "metadata": {},
   "outputs": [],
   "source": [
    "def createData(points, classes):\n",
    "    X = np.zeros((points*classes, 2))\n",
    "    y = np.zeros(points*classes, dtype='uint8')\n",
    "    for class_number in range(classes):\n",
    "        ix = range(points*class_number, points*(class_number+1))\n",
    "        r = np.linspace(0.0, 1, points)\n",
    "        t = np.linspace(class_number*4, (class_number+1)*4, points) + np.random.randn(points)*0.2\n",
    "        X[ix] = np.c_[r*np.sin(t*2.5), r*np.cos(t*2.5)]\n",
    "        y[ix] = class_number\n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "62d76c9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plotData(X, y):\n",
    "    plt.scatter(X[:,0], X[:,1])\n",
    "    plt.show()\n",
    "\n",
    "    plt.scatter(X[:,0], X[:,1], c=y, cmap=\"brg\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "fdb10426",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 5.11957148e-04 0.00000000e+00 1.14906097e-04\n",
      "  1.56964612e-03]\n",
      " [0.00000000e+00 1.03266675e-03 0.00000000e+00 2.22147887e-04\n",
      "  3.15134128e-03]\n",
      " ...\n",
      " [8.80520411e-02 3.87443779e-03 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [7.45596547e-02 1.64846014e-02 0.00000000e+00 0.00000000e+00\n",
      "  0.00000000e+00]\n",
      " [0.00000000e+00 7.29942983e-02 0.00000000e+00 0.00000000e+00\n",
      "  1.33861702e-01]]\n"
     ]
    }
   ],
   "source": [
    "X, y = createData(100, 3)\n",
    "# plotData(X, y)\n",
    "\n",
    "layer1 = DenseLayer(2, 5)\n",
    "activation1 = ReLU()\n",
    "\n",
    "layer1.forward(X)\n",
    "\n",
    "activation1.forward(layer1.output)\n",
    "print(activation1.output)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66fe4807",
   "metadata": {},
   "source": [
    "## Softmax Activation\n",
    "\n",
    "### Exponantiation to get rid of negative values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "35f468ef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[121.51041751873483, 3.353484652549023, 10.859062664920513]\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "layer_outputs = [4.8, 1.21, 2.385]\n",
    "E = math.e\n",
    "\n",
    "exp_values = []\n",
    "for output in layer_outputs:\n",
    "    exp_values.append(E**output)\n",
    "\n",
    "print(exp_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95bf1dc5",
   "metadata": {},
   "source": [
    "### Normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0ed154f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.8952826639572619, 0.024708306782099374, 0.0800090292606387]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "norm_base = sum(exp_values)\n",
    "norm_values = []\n",
    "\n",
    "for value in exp_values:\n",
    "    norm_values.append(value / norm_base)\n",
    "\n",
    "print(norm_values)\n",
    "print(sum(norm_values))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd66a043",
   "metadata": {},
   "source": [
    "### Using numpy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4adcaa9c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.89528266 0.02470831 0.08000903]\n"
     ]
    }
   ],
   "source": [
    "exp_values = np.exp(layer_outputs)\n",
    "norm_values = exp_values / np.sum(exp_values)\n",
    "\n",
    "print(norm_values)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b2a3fcb",
   "metadata": {},
   "source": [
    "### Turning input into batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "ae27a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8.95282664e-01 2.47083068e-02 8.00090293e-02]\n",
      " [9.99811129e-01 2.23163963e-05 1.66554348e-04]\n",
      " [5.13097164e-01 3.58333899e-01 1.28568936e-01]]\n",
      "0.9999999999999999\n"
     ]
    }
   ],
   "source": [
    "layer_outputs = [[4.8, 1.21, 2.385],\n",
    "                 [8.9, -1.81, 0.2],\n",
    "                 [1.41, 1.051, 0.026]]\n",
    "\n",
    "exp_values = np.exp(layer_outputs)\n",
    "norm_values = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "\n",
    "print(norm_values)\n",
    "print(norm_values[0][0] + norm_values[0][1] + norm_values[0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "495c9d22",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.33333333 0.33333333 0.33333333]\n",
      " [0.33328305 0.33337131 0.33334564]\n",
      " [0.33319169 0.3333926  0.3334157 ]\n",
      " [0.33325769 0.33339378 0.33334853]\n",
      " [0.33333333 0.33333333 0.33333333]]\n"
     ]
    }
   ],
   "source": [
    "class Softmax:\n",
    "    def forward(self, inputs):\n",
    "        exp_values = np.exp(inputs - np.max(inputs, axis=1, keepdims=True))\n",
    "        probabilites = exp_values / np.sum(exp_values, axis=1, keepdims=True)\n",
    "        self.output = probabilites\n",
    "\n",
    "X, y = createData(100, 3)\n",
    "\n",
    "dense1 = DenseLayer(2, 3)\n",
    "activation1 = ReLU()\n",
    "dense2 = DenseLayer(3, 3)\n",
    "activation2 = Softmax()\n",
    "\n",
    "dense1.forward(X)\n",
    "activation1.forward(dense1.output)\n",
    "dense2.forward(activation1.output)\n",
    "activation2.forward(dense2.output)\n",
    "\n",
    "print(activation2.output[:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f19e8e1e",
   "metadata": {},
   "source": [
    "## Loss function\n",
    "\n",
    "### Categorical Cross-Entropy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "a7e72ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.35667494393873245\n",
      "0.35667494393873245\n"
     ]
    }
   ],
   "source": [
    "softmax_output = [0.7, 0.1, 0.2]\n",
    "target_output = [1, 0, 0] # one-hot encoding\n",
    "\n",
    "loss = -(np.log(softmax_output[0])*target_output[0] + \n",
    "         np.log(softmax_output[1])*target_output[1] + \n",
    "         np.log(softmax_output[2])*target_output[2])\n",
    "\n",
    "print(loss)\n",
    "\n",
    "loss = -(np.log(softmax_output[0]))\n",
    "print(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.7 0.5 0.9]\n",
      "[0.7 0.5 0.9]\n",
      "0.38506088005216804\n"
     ]
    }
   ],
   "source": [
    "softmax_outputs = np.array([[0.7, 0.1, 0.2],\n",
    "                            [0.1, 0.5, 0.4],\n",
    "                            [0.02, 0.9, 0.08]])\n",
    "\n",
    "class_targets = [0, 1, 1] # for example, 0 means cat, 1 means dog, 2 means pigeon, so here the first input is a cat and the two others are dogs\n",
    "\n",
    "print(softmax_outputs[[0,1,2], class_targets]) # numpy magic, [0,1,2] selects all three rows of inputs\n",
    "print(softmax_outputs[range(len(softmax_outputs)), class_targets])\n",
    "\n",
    "neg_loss = -np.log(softmax_outputs[range(len(softmax_outputs)), class_targets])\n",
    "avg_loss = np.mean(neg_loss)\n",
    "print(avg_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5344ada8",
   "metadata": {},
   "source": [
    "**Problem:** neagtive log of 0 is infinity which results in errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "19295096",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loss:  1.098118544117172\n"
     ]
    }
   ],
   "source": [
    "class Loss:\n",
    "    def calculate(self, output, y):\n",
    "        sample_losses = self.forward(output, y)\n",
    "        data_loss = np.mean(sample_losses)\n",
    "        return data_loss\n",
    "\n",
    "class CategoricalCrossentropy(Loss):\n",
    "    def forward(self, y_pred, y_true):\n",
    "        samples = len(y_pred)\n",
    "        y_pred_clipped = np.clip(y_pred, 1e-7, 1-1e-7) # to resovle our problem\n",
    "\n",
    "        # check if scalar values or one hot encoded values have been passed\n",
    "        # scalar: [0, 1]\n",
    "        # one-hot encoded: [[1,0],[0,1]]\n",
    "        if len(y_true.shape) == 1:\n",
    "            correct_confidences = y_pred_clipped[range(samples), y_true]\n",
    "        else:\n",
    "            correct_confidences = np.sum(y_pred_clipped*y_true, axis=1)\n",
    "\n",
    "        negative_log_likelihoods = -np.log(correct_confidences)\n",
    "        return negative_log_likelihoods\n",
    "    \n",
    "loss_function = CategoricalCrossentropy()\n",
    "loss = loss_function.calculate(activation2.output, y)\n",
    "\n",
    "print(\"Loss: \", loss)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
